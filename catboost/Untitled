# %%
# imports
import pandas as pd
from catboost import CatBoostClassifier, Pool, cv
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import accuracy_score


#train = pd.read_csv('/Users/marcosanchez/Downloads/PROCESSED_MJD_TRAIN.csv')
#test = pd.read_csv('/Users/marcosanchez/Downloads/PROCESSED_MJD_TEST.csv')

# %%
# temp data until full data is ready
temp = pd.read_csv('/Users/marcosanchez/MajoranaHunt/results.csv')

X = temp.drop(['highavse', 'lowavse', 'truedcr', 'lq'], axis=1)
y = temp["highavse"]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# %%
"""
train_data = train.drop(['highavse', 'lowavse', 'truedcr', 'lq'], axis = 1)
train_target = temp['highavse']

test_data =
test_target =
"""

#model training
model = CatBoostClassifier(
    iterations=500,
    learning_rate=0.1,
    depth=6,
    verbose=50
)

model.fit(X_train, y_train)


# %%
pred = model.predict(X_test)
print(f"Accuracy: {accuracy_score(y_test, pred)}")

# %%
# finding feature importance
features = model.get_feature_importance()
names = X_train.columns

for name, importance in zip(names, features):
    print(f"{name}: {importance}")

# %%
# cross validation
train_pool = Pool(X_train, y_train)

params = {
    'iterations': 500,
    'learning_rate': 0.1,
    'depth': 6,
    'loss_function': 'Logloss'
}

cv_results = cv(
    pool=train_pool,
    params=params,
    fold_count=5,
    verbose=False
)

print(cv_results)


# %%
#hyperparameter tuning

model = CatBoostClassifier(verbose=0)

param_grid = {
    'iterations': [100, 500, 1000],
    'learning_rate': [0.01, 0.1, 0.3],
    'depth': [4, 6, 10]
}

grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, scoring='accuracy')
grid_search.fit(X_train, y_train)

print(grid_search.best_params_)
print(grid_search.best_score_)
